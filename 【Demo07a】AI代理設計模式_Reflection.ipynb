{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6e9d19",
   "metadata": {},
   "source": [
    "# To-do List\n",
    "# Abstract\n",
    "According to the course requirements, we are tasked with building an LLM application based on the Reflection Module.\n",
    "\n",
    "Therefore, in this assignment, I will simulate a real-world scenario to enhance a RAG-based Threat Intelligence Security Chatbot using the Reflection Module.\n",
    "\n",
    "# 1. Introduction\n",
    "## 1.1. Reflection Module\n",
    "The Reflection Module consists of three key stages:\n",
    "\n",
    "Firstly, it processes the user's input using an LLM.\n",
    "\n",
    "Secondly, it uses the LLM again to refine the initial output.\n",
    "\n",
    "Finally, it generates the improved result.\n",
    "\n",
    "## 1.2. Enhancing RAG Applications with the Reflection Module\n",
    "In cybersecurity scenarios—whether in threat intelligence reports or online articles—researchers often use highly technical or obscure terminology. This makes it difficult to directly map a user's input to relevant documents in a Threat Intelligence Database using vector search alone, often leading to misinterpretations.\n",
    "\n",
    "To address this, we propose using the Reflection Module to pre-process and refine user input. By transforming non-expert language into more professional and domain-specific terms, we aim to improve the relevance and accuracy of vector search results.\n",
    "\n",
    "# 2. Development\n",
    "Based on the aforementioned considerations,\n",
    "In this assignment for the course \"AI Agent: Reflection Module\", I will develop a security chatbot with the following features:\n",
    "\n",
    "Reflection Module-enhanced Chatbot\n",
    "\n",
    "Threat Intelligence-aware Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82512f6",
   "metadata": {},
   "source": [
    "# Reflection Module Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4f2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "reflection_client = OpenAI(\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "def reply(system_prompt,\n",
    "          user_prompt\n",
    "          ):\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    chat_completion = reflection_client.chat.completions.create(\n",
    "        model= \"gpt-4o-mini\", # save money\n",
    "        messages= messages,\n",
    "        max_tokens= 500 # cot very expensive must be limit output token.\n",
    "    )\n",
    "\n",
    "\n",
    "    reply = chat_completion.choices[0].message.content\n",
    "\n",
    "    return reply\n",
    "\n",
    "def reflect_post(user_prompt):\n",
    "    # Step 1: Writer 初稿\n",
    "    system_writer = \"你是一個優秀的資安分析顧問，請幫助使用者梳理情境，將使用者較不專業的言語轉換為適合用於威脅情資的版本\"\n",
    "    first_version = reply(system_prompt= system_writer, \n",
    "                          user_prompt = user_prompt\n",
    "                          )\n",
    "\n",
    "\n",
    "    # Step 2: Reviewer 給建議\n",
    "    system_reviewer = \"你是一位資安文案潤稿專家，擅長分析一篇威脅情資是否足夠專業，並給出建議。\"\n",
    "    suggestion = reply(system_prompt= system_reviewer, \n",
    "                        user_prompt = first_version\n",
    "                        )\n",
    "\n",
    "\n",
    "    # Step 3: Writer 再寫一次（根據建議）\n",
    "    second_system_prompt = \"你是個優化的資安顧問，善於根據修改意見優化威脅情資的結構\"\n",
    "    second_prompt = f\"這是我剛剛寫的貼文：\\n{first_version}\\n\\n這是修改建議：\\n{suggestion}\\n\\n請根據這些建議，幫我改得更生活化、更自然。請用台灣習慣的中文, 並且只要輸出改好的文章就可以了。\"\n",
    "\n",
    "    second_version = reply(system_prompt= second_system_prompt, \n",
    "                            user_prompt = second_prompt\n",
    "                            )\n",
    "    \n",
    "    return first_version, suggestion, second_version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331a5a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio\n",
    "with gradio.Blocks() as demo:\n",
    "    gradio.Markdown(\"### 🤖 資安威脅描述優化（Reflection Agent）\")\n",
    "    user_input = gradio.Textbox(label=\"請輸入你今天發現的資安事件\")\n",
    "    btn = gradio.Button(\"生成貼文 & 修正建議\")\n",
    "\n",
    "    with gradio.Row():\n",
    "        out1 = gradio.Textbox(label=\"🌟 第一版貼文 (model_writer)\")\n",
    "        out2 = gradio.Textbox(label=\"🧐 修改建議 (model_reviewer)\")\n",
    "        out3 = gradio.Textbox(label=\"✨ 第二版貼文 (model_writer 改寫)\")\n",
    "\n",
    "    btn.click(reflect_post, inputs=[user_input], outputs=[out1, out2, out3])\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c13a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = '''\n",
    "    My desktop is showing a 24-hour countdown, demanding that I pay in Bitcoin to unlock it, or else my data will be stolen.\n",
    "\n",
    "    I just discovered a strange folder placed in the root directory of my Windows system. It's named \"ysytem32\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d04b1",
   "metadata": {},
   "source": [
    "# Threat Intellgence Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "import pandas\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document \n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# cot prompt + RAG\n",
    "system_prompt_templete = '''\n",
    "    你是一個優秀的資安分析師，現在需要幫助使用者分辨當前的情境屬於何種資安威脅。並參考威脅情資內容後，根據以下內容 Step by Step 分析。\n",
    "    參考情資與使用者情境分析，\n",
    "    1. 使用者可能是如何被入侵的\n",
    "    2. 使用者目前可以先做何種緩解措施\n",
    "'''\n",
    "\n",
    "# RAG Post\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"data/faiss_db\",\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt_templete}\n",
    "            ]\n",
    "\n",
    "import gradio\n",
    "with gradio.Blocks() as demo:\n",
    "    gradio.Markdown(\"# Professional Security Consulting\")\n",
    "    chatbot = gradio.Chatbot(type=\"messages\")\n",
    "    msg = gradio.Textbox(placeholder=\"請輸入你的問題...\")\n",
    "    state = gradio.State(messages)\n",
    "\n",
    "    def main_chatbot(user_prompt, messages):\n",
    "        results = vectorstore.similarity_search(user_prompt, k=1)\n",
    "        RAG_Post = results[0].page_content\n",
    "        user_prompt_templete = '''\n",
    "            使用者情境\n",
    "                {user_prompt}\n",
    "            威脅情資  \n",
    "                {RAG_Post}\n",
    "        '''\n",
    "\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt_templete.format(user_prompt = user_prompt, RAG_Post= RAG_Post)})\n",
    "\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model= \"gpt-4o-mini\", # save money\n",
    "            messages= messages,\n",
    "            max_tokens= 500 # cot very expensive must be limit output token.\n",
    "        )\n",
    "\n",
    "        reply = chat_completion.choices[0].message.content\n",
    "        messages.append({\"role\": \"assistant\", \"content\": reply}) # 透過添加歷史對話紀錄，變相讓 LLM 記得說了些什麼。改成這個寫法之後要 debug 也會比較方便。\n",
    "\n",
    "        return \"\", messages, messages\n",
    "\n",
    "    msg.submit(\n",
    "            fn=main_chatbot,\n",
    "            inputs=[msg, state],\n",
    "            outputs=[msg, chatbot, state]\n",
    "        )\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2f712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
